# -*- coding: utf-8 -*-
"""è¿æ¥å™¨APIè·¯ç”±"""
from pickle import FALSE

from sanic import Blueprint, Request
from sanic.response import json, ResponseStream
import ujson as json_lib
import asyncio
from services.sniper.connectors import ConnectorService
from utils.logger import logger
from utils.exceptions import BusinessException, RateLimitException, LockConflictException, ContextNotFoundException
from api.schema.base import BaseResponse, ErrorCode, ErrorMessage
from api.schema.connectors import ExtractRequest, HarvestRequest, PublishRequest, LoginRequest, SearchRequest
from pydantic import BaseModel, Field, ValidationError
from models.connectors import PlatformType, LoginMethod
from models.task import Task

# åˆ›å»ºè“å›¾
connectors_bp = Blueprint("connectors", url_prefix="/connectors")



# ==================== è·¯ç”±å¤„ç† ====================

@connectors_bp.post("/extract-summary")
async def extract_summary(request: Request):
    """æå–URLå†…å®¹æ‘˜è¦ - SSE æµå¼è¾“å‡º"""

    async def stream_response(response):
        try:
            data = ExtractRequest.model_validate(request.json)
        except ValidationError as e:
            # å‚æ•°éªŒè¯å¤±è´¥ï¼Œå‘é€é”™è¯¯äº‹ä»¶
            await response.write(f"data: {json_lib.dumps({'type': 'error', 'message': f'å‚æ•°éªŒè¯å¤±è´¥: {str(e)}', 'data': {'error_type': 'validation_error'}}, ensure_ascii=False)}\n\n")
            return
        except Exception as e:
            # å…¶ä»–é”™è¯¯
            await response.write(f"data: {json_lib.dumps({'type': 'error', 'message': f'è¯·æ±‚æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}', 'data': {'error_type': 'request_error'}}, ensure_ascii=False)}\n\n")
            return
        
        # è·å–è®¤è¯ä¸Šä¸‹æ–‡
        auth_info = request.ctx.auth_info
        connector_service = ConnectorService(request.app.ctx.playwright, auth_info.source.value, auth_info.source_id)
        # æµå¼è·å–ç»“æœå¹¶å‘é€SSEäº‹ä»¶
        async for event in connector_service.extract_summary_stream(
            urls=data.urls,
            platform=data.platform,
            concurrency=data.concurrency
        ):
            await response.write(f"data: {json_lib.dumps(event, ensure_ascii=False)}\n\n")

    return ResponseStream(
        stream_response,
        headers={
            "Content-Type": "text/event-stream",
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )

@connectors_bp.post("/harvest")
async def harvest_content(request: Request):
    """é‡‡æ”¶ç”¨æˆ·å†…å®¹"""
    try:
        data = HarvestRequest(**request.json)
        logger.info(f"æ”¶åˆ°é‡‡æ”¶è¯·æ±‚: platform={data.platform}, user_id={data.creator_ids}, limit={data.limit}")

        # è·å–è®¤è¯ä¸Šä¸‹æ–‡
        auth_info = request.ctx.auth_info

        # åˆ›å»ºå¹¶å¯åŠ¨ä»»åŠ¡
        task = await Task.create(
            source=auth_info.source.value,
            source_id=auth_info.source_id,
            task_type="harvest_content"
        )
        await task.start()

        async with ConnectorService(request.app.ctx.playwright, auth_info.source.value, auth_info.source_id, task=task) as connector_service:
            results = await connector_service.harvest_user_content(
                platform=data.platform,
                creator_ids=data.creator_ids,
                limit=data.limit
            )

            # é‡ç»„ç»“æœï¼šæŒ‰ creator_id åˆ†ç»„
            results_by_creator = {}
            successful_creators = 0
            failed_creators = 0
            total_notes = 0

            for result in results:
                creator_id = result.get("creator_id")
                if creator_id:
                    if result.get("success"):
                        notes = result.get("data", [])
                        results_by_creator[creator_id] = {
                            "success": True,
                            "note_count": len(notes),
                            "notes": notes
                        }
                        successful_creators += 1
                        total_notes += len(notes)
                    else:
                        results_by_creator[creator_id] = {
                            "success": False,
                            "error": result.get("error"),
                            "note_count": 0,
                            "notes": []
                        }
                        failed_creators += 1

            # å®Œæˆä»»åŠ¡
            await task.complete({
                "total_creators": len(data.creator_ids),
                "successful_creators": successful_creators,
                "total_notes": total_notes
            })

            return json(BaseResponse(
                code=ErrorCode.SUCCESS,
                message=f"é‡‡æ”¶å®Œæˆï¼š{successful_creators}/{len(data.creator_ids)} ä¸ªåˆ›ä½œè€…æˆåŠŸï¼Œå…± {total_notes} æ¡ç¬”è®°",
                data={
                    "task_id": str(task.id),
                    "total_creators": len(data.creator_ids),
                    "successful_creators": successful_creators,
                    "failed_creators": failed_creators,
                    "total_notes": total_notes,
                    "results": results_by_creator
                }
            ).model_dump())

    except ValidationError as e:
        logger.error(f"å‚æ•°éªŒè¯å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.VALIDATION_ERROR,
            message=ErrorMessage.VALIDATION_ERROR,
            data={"detail": str(e)}
        ).model_dump(), status=400)
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return json(BaseResponse(
            code=ErrorCode.BAD_REQUEST,
            message=str(e),
            data={"error": str(e)}
        ).model_dump(), status=400)
    except Exception as e:
        logger.error(f"é‡‡æ”¶å†…å®¹å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.INTERNAL_ERROR,
            message=ErrorMessage.INTERNAL_ERROR,
            data={"error": str(e)}
        ).model_dump(), status=500)


@connectors_bp.post("/publish")
async def publish_content(request: Request):
    """å‘å¸ƒå†…å®¹åˆ°å¹³å°"""
    try:
        data = PublishRequest(**request.json)
        logger.info(f"æ”¶åˆ°å‘å¸ƒè¯·æ±‚: platform={data.platform}, type={data.content_type}")

        # è·å–è®¤è¯ä¸Šä¸‹æ–‡
        auth_info = request.ctx.auth_info

        # åˆ›å»ºå¹¶å¯åŠ¨ä»»åŠ¡
        task = await Task.create(
            source=auth_info.source.value,
            source_id=auth_info.source_id,
            task_type="publish_content"
        )
        await task.start()

        async with ConnectorService(request.app.ctx.playwright, auth_info.source.value, auth_info.source_id, task=task) as connector_service:
            result = await connector_service.publish_content(
                platform=data.platform,
                content=data.content,
                content_type=data.content_type,
                images=data.images or [],
                tags=data.tags or []
            )

            # å®Œæˆä»»åŠ¡
            await task.complete({"success": result.get("success", False)})

            return json(BaseResponse(
                code=ErrorCode.SUCCESS if result.get("success") else ErrorCode.INTERNAL_ERROR,
                message="å‘å¸ƒæˆåŠŸ" if result.get("success") else "å‘å¸ƒå¤±è´¥",
                data={
                    "task_id": str(task.id),
                    **result
                }
            ).model_dump())

    except ValidationError as e:
        logger.error(f"å‚æ•°éªŒè¯å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.VALIDATION_ERROR,
            message=ErrorMessage.VALIDATION_ERROR,
            data={"detail": str(e)}
        ).model_dump(), status=400)
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return json(BaseResponse(
            code=ErrorCode.BAD_REQUEST,
            message=str(e),
            data={"error": str(e)}
        ).model_dump(), status=400)
    except Exception as e:
        logger.error(f"å‘å¸ƒå†…å®¹å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.INTERNAL_ERROR,
            message=ErrorMessage.INTERNAL_ERROR,
            data={"error": str(e)}
        ).model_dump(), status=500)


@connectors_bp.post("/login")
async def login(request: Request):
    """ç™»å½•å¹³å°"""
    try:
        data = LoginRequest(**request.json)
        logger.info(f"æ”¶åˆ°ç™»å½•è¯·æ±‚: platform={data.platform}, method={data.method}")

        # è·å–è®¤è¯ä¸Šä¸‹æ–‡
        auth_info = request.ctx.auth_info

        # åˆ›å»ºå¹¶å¯åŠ¨ä»»åŠ¡
        task = await Task.create(
            source=auth_info.source.value,
            source_id=auth_info.source_id,
            task_type="login"
        )
        await task.start()

        async with ConnectorService(request.app.ctx.playwright, auth_info.source.value, auth_info.source_id, task=task) as connector_service:
            logger.info(f"[Auth] ä»è®¤è¯ä¸Šä¸‹æ–‡è·å–: é‰´æƒæ•°æ®AuthInfo: {auth_info.source}")

            # è°ƒç”¨ connector_service çš„ login æ–¹æ³•
            result = await connector_service.login(
                platform=data.platform,
                method=data.method,
                cookies=data.cookies or {}
            )

            # å®Œæˆä»»åŠ¡
            await task.complete({"success": bool(result)})

            # æ ¹æ®ç™»å½•æ–¹æ³•å¤„ç†ä¸åŒè¿”å›æ ¼å¼
            if data.method == LoginMethod.QRCODE:
                # äºŒç»´ç ç™»å½•è¿”å›å­—å…¸ï¼ŒåŒ…å« qrcode, context_id, is_logged_in ç­‰
                return json(BaseResponse(
                    code=ErrorCode.SUCCESS if result.get("success") else ErrorCode.INTERNAL_ERROR,
                    message=result.get("message", "ç™»å½•è¯·æ±‚å¤„ç†å®Œæˆ"),
                    data={
                        "task_id": str(task.id),
                        **result,  # åŒ…å« qrcode, context_id, is_logged_in, timeout ç­‰
                        "source": auth_info.source,
                        "source_id": auth_info.source_id
                    }
                ).model_dump())
            else:
                # Cookie ç™»å½•è¿”å› context_id å­—ç¬¦ä¸²
                return json(BaseResponse(
                    code=ErrorCode.SUCCESS if result else ErrorCode.INTERNAL_ERROR,
                    message="ç™»å½•æˆåŠŸ" if result else "ç™»å½•å¤±è´¥",
                    data={
                        "task_id": str(task.id),
                        "context_id": result,
                        "source": auth_info.source,
                        "source_id": auth_info.source_id
                    }
                ).model_dump())

    except ValidationError as e:
        logger.error(f"å‚æ•°éªŒè¯å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.VALIDATION_ERROR,
            message=ErrorMessage.VALIDATION_ERROR,
            data={"detail": str(e)}
        ).model_dump(), status=400)
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return json(BaseResponse(
            code=ErrorCode.BAD_REQUEST,
            message=str(e),
            data={"error": str(e)}
        ).model_dump(), status=400)
    except Exception as e:
        logger.error(f"ç™»å½•å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.INTERNAL_ERROR,
            message=ErrorMessage.INTERNAL_ERROR,
            data={"error": str(e)}
        ).model_dump(), status=500)


@connectors_bp.post("/login/<platform:str>/confirm")
async def confirm_login(request: Request, platform: str):
    """ç”¨æˆ·ç¡®è®¤å·²å®Œæˆç™»å½• - ä¿å­˜ context

    ç”¨æˆ·åœ¨äº‘æµè§ˆå™¨ä¸­å®Œæˆç™»å½•åï¼Œç‚¹å‡»"æˆ‘å·²å®Œæˆç™»å½•"æŒ‰é’®è°ƒç”¨æ­¤æ¥å£ï¼š
    1. ä» connector._login_tasks è·å– session å’Œ browser
    2. è°ƒç”¨ _cleanup_resources æ¸…ç†èµ„æº
    3. è°ƒç”¨ agent_bay.delete(session, sync_context=True) è½ç›˜ä¿å­˜
    """
    try:
        data = request.json or {}
        context_id = data.get("context_id")

        if not context_id:
            return json(BaseResponse(
                code=ErrorCode.BAD_REQUEST,
                message="context_id is required",
                data=None
            ).model_dump(), status=400)

        auth_info = request.ctx.auth_info

        # è·å– connector
        from models.connectors import PlatformType
        from services.sniper.connectors.xiaohongshu import XiaohongshuConnector
        from services.sniper.connectors.douyin import DouyinConnector

        try:
            platform_type = PlatformType(platform)
        except ValueError:
            return json(BaseResponse(
                code=ErrorCode.BAD_REQUEST,
                message=f"Unsupported platform: {platform}",
                data=None
            ).model_dump(), status=400)

        # åˆ›å»º connector å®ä¾‹
        if platform_type == PlatformType.XIAOHONGSHU:
            connector = XiaohongshuConnector(playwright=request.app.ctx.playwright)
        elif platform_type == PlatformType.DOUYIN:
            connector = DouyinConnector(playwright=request.app.ctx.playwright)
        else:
            return json(BaseResponse(
                code=ErrorCode.BAD_REQUEST,
                message=f"Platform {platform} not supported yet",
                data=None
            ).model_dump(), status=400)

        # ä» _login_tasks è·å– session å’Œ browser
        if context_id not in connector._login_tasks:
            return json(BaseResponse(
                code=ErrorCode.NOT_FOUND,
                message=f"Login task not found for context: {context_id}",
                data=None
            ).model_dump(), status=404)

        login_task = connector._login_tasks[context_id]
        session = login_task.get("session")
        browser = login_task.get("browser")

        if not session:
            return json(BaseResponse(
                code=ErrorCode.INTERNAL_ERROR,
                message="Session not found in login task",
                data=None
            ).model_dump(), status=500)

        # æ¸…ç†èµ„æºå¹¶ä¿å­˜ context
        logger.info(f"[Auth] User confirmed login for {platform}, saving context: {context_id}")

        try:
            # è°ƒç”¨ connector çš„ _cleanup_resources æ–¹æ³•
            await connector._cleanup_resources(session, browser)

            # ä¿å­˜ contextï¼ˆsync_context=True è½ç›˜ï¼‰
            await connector.agent_bay.delete(session, sync_context=True)

            logger.info(f"[Auth] Context saved successfully: {context_id}")

        except Exception as e:
            logger.error(f"[Auth] Error saving context: {e}")
            # å³ä½¿å‡ºé”™ä¹Ÿç»§ç»­ï¼Œå› ä¸º context å¯èƒ½å·²ç»ä¿å­˜

        # æ¸…ç† _login_tasks
        del connector._login_tasks[context_id]

        return json(BaseResponse(
            code=ErrorCode.SUCCESS,
            message="Login context saved successfully",
            data={
                "context_id": context_id,
                "platform": platform,
                "source": auth_info.source.value,
                "source_id": auth_info.source_id
            }
        ).model_dump())

    except Exception as e:
        logger.error(f"ç¡®è®¤ç™»å½•å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.INTERNAL_ERROR,
            message=str(e),
            data={"error": str(e)}
        ).model_dump(), status=500)


@connectors_bp.get("/platforms")
async def list_platforms(request: Request):
    """è·å–æ”¯æŒçš„å¹³å°åˆ—è¡¨ - å±•ç¤ºå¤šå¹³å°è¿æ¥èƒ½åŠ›"""
    platforms = [
        {
            "name": PlatformType.XIAOHONGSHU.value,
            "display_name": "å°çº¢ä¹¦",
            "icon": "ğŸ“•",
            "category": "ç¤¾äº¤å†…å®¹",
            "features": {
                "extract": {
                    "enabled": True,
                    "description": "AI é©±åŠ¨çš„å†…å®¹æ‘˜è¦æå–",
                    "modes": ["stream", "batch"]
                },
                "get_note_detail": {
                    "enabled": True,
                    "description": "å¿«é€Ÿè·å–ç¬”è®°è¯¦æƒ…ï¼ˆCDP ç›´è¿ï¼‰",
                    "performance": "~2-5ç§’/ç¯‡"
                },
                "harvest": {
                    "enabled": True,
                    "description": "æ‰¹é‡é‡‡æ”¶ç”¨æˆ·ä¸»é¡µå†…å®¹",
                    "max_limit": 100
                },
                "search": {
                    "enabled": True,
                    "description": "å…³é”®è¯æœç´¢å¹¶æå–"
                },
                "publish": {
                    "enabled": True,
                    "description": "å‘å¸ƒå†…å®¹åˆ°å¹³å°",
                    "supported_types": ["text", "image", "video"]
                },
                "login": {
                    "enabled": True,
                    "methods": ["cookie", "qrcode"],
                    "description": "æ”¯æŒ Cookie å’ŒäºŒç»´ç ç™»å½•"
                }
            },
            "rate_limits": {
                "get_note_detail": "10æ¬¡/60ç§’",
                "harvest": "5æ¬¡/60ç§’",
                "search": "10æ¬¡/60ç§’",
                "publish": "2æ¬¡/60ç§’"
            },
            "domain_patterns": ["xiaohongshu.com", "xhslink.com"]
        },
        {
            "name": PlatformType.WECHAT.value,
            "display_name": "å¾®ä¿¡å…¬ä¼—å·",
            "icon": "ğŸ’¬",
            "category": "å†…å®¹å¹³å°",
            "features": {
                "extract": {
                    "enabled": True,
                    "description": "AI é©±åŠ¨çš„æ–‡ç« æ‘˜è¦æå–",
                    "modes": ["stream", "batch"]
                },
                "get_note_detail": {
                    "enabled": True,
                    "description": "å¿«é€Ÿè·å–æ–‡ç« è¯¦æƒ…ï¼ˆCDP ç›´è¿ï¼‰",
                    "performance": "~2-5ç§’/ç¯‡"
                },
                "harvest": {
                    "enabled": True,
                    "description": "æ‰¹é‡é‡‡æ”¶å…¬ä¼—å·æ–‡ç« ",
                    "max_limit": 100
                },
                "search": {
                    "enabled": False,
                    "description": "æš‚ä¸æ”¯æŒ"
                },
                "publish": {
                    "enabled": False,
                    "description": "æš‚ä¸æ”¯æŒ"
                },
                "login": {
                    "enabled": False,
                    "description": "æ— éœ€ç™»å½•ï¼ˆå…¬å¼€æ–‡ç« ï¼‰"
                }
            },
            "rate_limits": {
                "get_note_detail": "10æ¬¡/60ç§’",
                "harvest": "5æ¬¡/60ç§’"
            },
            "domain_patterns": ["mp.weixin.qq.com"]
        },
        {
            "name": PlatformType.GENERIC.value,
            "display_name": "é€šç”¨ç½‘ç«™",
            "icon": "ğŸŒ",
            "category": "é€šç”¨å·¥å…·",
            "features": {
                "extract": {
                    "enabled": True,
                    "description": "AI é©±åŠ¨çš„é€šç”¨å†…å®¹æå–",
                    "modes": ["stream", "batch"]
                },
                "get_note_detail": {
                    "enabled": False,
                    "description": "æš‚ä¸æ”¯æŒ"
                },
                "harvest": {
                    "enabled": False,
                    "description": "æš‚ä¸æ”¯æŒ"
                },
                "search": {
                    "enabled": False,
                    "description": "æš‚ä¸æ”¯æŒ"
                },
                "publish": {
                    "enabled": False,
                    "description": "æš‚ä¸æ”¯æŒ"
                },
                "login": {
                    "enabled": False,
                    "description": "æš‚ä¸æ”¯æŒ"
                }
            },
            "rate_limits": {
                "extract": "10æ¬¡/60ç§’"
            },
            "domain_patterns": ["*"]
        }
    ]

    return json(BaseResponse(
        code=ErrorCode.SUCCESS,
        message="è·å–å¹³å°åˆ—è¡¨æˆåŠŸ",
        data={
            "platforms": platforms,
            "total": len(platforms),
            "summary": {
                "supported_platforms": len(platforms),
                "content_extraction": sum(1 for p in platforms if p["features"]["extract"]["enabled"]),
                "detail_fetching": sum(1 for p in platforms if p["features"]["get_note_detail"]["enabled"]),
                "harvest": sum(1 for p in platforms if p["features"]["harvest"]["enabled"]),
                "publish": sum(1 for p in platforms if p["features"]["publish"]["enabled"]),
                "search": sum(1 for p in platforms if p["features"]["search"]["enabled"])
            }
        }
    ).model_dump())


@connectors_bp.post("/get-note-detail")
async def get_note_detail(request: Request):
    """è·å–ç¬”è®°/æ–‡ç« è¯¦æƒ…ï¼ˆå¿«é€Ÿæå–ï¼Œä¸ä½¿ç”¨Agentï¼‰

    é€‚åˆåœºæ™¯ï¼š
    - æ‰¹é‡è·å–æ–‡ç« å†…å®¹å’Œå›¾ç‰‡
    - å¿«é€ŸæŠ“å–æ–‡ç« åŸºæœ¬ä¿¡æ¯
    - ä¸éœ€è¦æ·±åº¦AIåˆ†æçš„åœºæ™¯

    æ€§èƒ½ç‰¹ç‚¹ï¼š
    - é€Ÿåº¦å¿«ï¼Œé€šå¸¸2-5ç§’å®Œæˆå•ç¯‡æ–‡ç« 
    - èµ„æºæ¶ˆè€—å°‘
    - ç›´æ¥æå–ï¼Œä¸ä¾èµ–AI
    """
    try:
        data = ExtractRequest(**request.json)
        logger.info(f"æ”¶åˆ°å¿«é€Ÿæå–è¯·æ±‚: {len(data.urls)} ä¸ªURL, platform={data.platform}")

        # è·å–è®¤è¯ä¸Šä¸‹æ–‡
        auth_info = request.ctx.auth_info

        # åˆ›å»ºå¹¶å¯åŠ¨ä»»åŠ¡
        task = await Task.create(
            source=auth_info.source.value,
            source_id=auth_info.source_id,
            task_type="get_note_detail"
        )
        await task.start()

        async with ConnectorService(request.app.ctx.playwright, auth_info.source.value, auth_info.source_id, task=task) as connector_service:
            # è·å–ç¬”è®°è¯¦æƒ…
            results = await connector_service.get_note_details(
                urls=data.urls,
                platform=data.platform
            )

            # ç»Ÿè®¡ç»“æœ
            success_count = sum(1 for r in results if r.get("success"))

            # å®Œæˆä»»åŠ¡
            await task.complete({
                "total": len(results),
                "success_count": success_count
            })

            return json(BaseResponse(
                code=ErrorCode.SUCCESS,
                message=f"å¿«é€Ÿæå–å®Œæˆï¼š{success_count}/{len(results)} æˆåŠŸ",
                data={
                    "task_id": str(task.id),
                    "results": results,
                    "summary": {
                        "total": len(results),
                        "success_count": success_count,
                        "failed_count": len(results) - success_count,
                        "method": "fast_extraction"
                    }
                }
            ).model_dump())

    except ValidationError as e:
        logger.error(f"å‚æ•°éªŒè¯å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.VALIDATION_ERROR,
            message=ErrorMessage.VALIDATION_ERROR,
            data={"detail": str(e)}
        ).model_dump(), status=400)
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return json(BaseResponse(
            code=ErrorCode.BAD_REQUEST,
            message=str(e),
            data={"error": str(e)}
        ).model_dump(), status=400)
    except Exception as e:
        logger.error(f"è·å–ç¬”è®°è¯¦æƒ…å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.INTERNAL_ERROR,
            message=ErrorMessage.INTERNAL_ERROR,
            data={"error": str(e)}
        ).model_dump(), status=500)


@connectors_bp.post("/search-and-extract")
async def search_and_extract(request: Request):
    """æœç´¢å¹¶æå–å†…å®¹"""
    try:
        data = SearchRequest.model_validate(request.json)
        logger.info(f"æœç´¢å¹¶æå–å†…å®¹: platform={data.platform}, keywords={data.keywords}")

        # è·å–è®¤è¯ä¸Šä¸‹æ–‡
        auth_info = request.ctx.auth_info

        # åˆ›å»ºå¹¶å¯åŠ¨ä»»åŠ¡
        task = await Task.create(
            source=auth_info.source.value,
            source_id=auth_info.source_id,
            task_type="search_and_extract"
        )
        await task.start()

        async with ConnectorService(request.app.ctx.playwright, auth_info.source.value, auth_info.source_id, task=task) as connector_service:
            results = await connector_service.search_and_extract(
                platform=data.platform,
                keywords=data.keywords,
                limit=data.limit
            )

            # é‡ç»„ç»“æœï¼šæŒ‰ keyword åˆ†ç»„
            results_by_keyword = {}
            successful_keywords = 0
            failed_keywords = 0
            total_results = 0

            for result in results:
                keyword = result.get("keyword")
                if keyword:
                    if result.get("success"):
                        items = result.get("data", [])
                        results_by_keyword[keyword] = {
                            "success": True,
                            "result_count": len(items),
                            "results": items
                        }
                        successful_keywords += 1
                        total_results += len(items)
                    else:
                        results_by_keyword[keyword] = {
                            "success": False,
                            "error": result.get("error"),
                            "result_count": 0,
                            "results": []
                        }
                        failed_keywords += 1

            # å®Œæˆä»»åŠ¡
            await task.complete({
                "total_keywords": len(data.keywords),
                "successful_keywords": successful_keywords,
                "total_results": total_results
            })

            return json(BaseResponse(
                code=ErrorCode.SUCCESS,
                message=f"æœç´¢å®Œæˆï¼š{successful_keywords}/{len(data.keywords)} ä¸ªå…³é”®è¯æˆåŠŸï¼Œå…± {total_results} æ¡ç»“æœ",
                data={
                    "task_id": str(task.id),
                    "total_keywords": len(data.keywords),
                    "successful_keywords": successful_keywords,
                    "failed_keywords": failed_keywords,
                    "total_results": total_results,
                    "results": results_by_keyword
                }
            ).model_dump())

    except ValidationError as e:
        logger.error(f"å‚æ•°éªŒè¯å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.VALIDATION_ERROR,
            message=ErrorMessage.VALIDATION_ERROR,
            data={"detail": str(e)}
        ).model_dump(), status=400)
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return json(BaseResponse(
            code=ErrorCode.BAD_REQUEST,
            message=str(e),
            data={"error": str(e)}
        ).model_dump(), status=400)
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        return json(BaseResponse(
            code=ErrorCode.INTERNAL_ERROR,
            message=ErrorMessage.INTERNAL_ERROR,
            data={"error": str(e)}
        ).model_dump(), status=500)
